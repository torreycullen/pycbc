

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>The workflow postprocessing preparation module &mdash; PyCBC 0.1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="PyCBC 0.1 documentation" href="../index.html"/>
        <link rel="up" title="Workflow: the inspiral analysis workflow generator (pycbc.workflow)" href="../workflow.html"/>
        <link rel="next" title="The workflow postprocessing module" href="postproc.html"/>
        <link rel="prev" title="HDF5 Based Coincidence Code" href="hdf_coincidence.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> PyCBC
          

          
          </a>

          
            
            
              <div class="version">
                1.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing PyCBC</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pycbc_make_psd_estimation_workflow.html"><code class="docutils literal"><span class="pre">pycbc_make_psd_estimation_workflow</span></code>: A workflow generator for noise estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pycbc_make_coinc_search_workflow.html"><code class="docutils literal"><span class="pre">pycbc_make_coinc_search_workflow</span></code>: A workflow to search for gravitational waves</a></li>
<li class="toctree-l1"><a class="reference internal" href="pycbc_make_sngl_workflow.html"><code class="docutils literal"><span class="pre">pycbc_make_sngl_workflow</span></code>: A single-ifo detchar workflow generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="pygrb.html"><code class="docutils literal"><span class="pre">pycbc_make_offline_grb_workflow</span></code>: A GRB triggered CBC analysis workflow generator</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tmpltbank.html">PyCBC template bank generation documentation (<code class="docutils literal"><span class="pre">pycbc.tmpltbank</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hwinj.html">Hardware injection waveform generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../banksim.html">Calculating the Effectualness (Fitting Factor) of Template Banks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faithsim.html">Dag Generator for Doing Faithfulness Comparisons</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../waveform.html">Waveforms</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../documentation.html">Documenting PyCBC code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release.html">Creating Releases of PyCBC</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../frame.html">Reading Gravitational-wave Frames (<code class="docutils literal"><span class="pre">pycbc.frame</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../formats/hdf_format.html">HDF files within the PyCBC workflow</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../workflow.html">Workflow: the inspiral analysis workflow generator (<code class="docutils literal"><span class="pre">pycbc.workflow</span></code>)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../workflow.html#introduction">Introduction</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../workflow.html#workflow-module-documentation">Workflow module documentation</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#initialization">Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#generating-segments">Generating segments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#obtaining-data">Obtaining data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#injection-generation">Injection generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#time-slide-generation">Time-slide generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#template-bank">Template bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#split-table">Split table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#matched-filtering">Matched-filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#coincidence">Coincidence</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../workflow.html#post-processing-preparation">Post processing preparation</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="">The workflow postprocessing preparation module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#post-processing">Post-processing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../workflow.html#method-documentation">Method documentation</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">pycbc</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">PyCBC</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../workflow.html">Workflow: the inspiral analysis workflow generator (<code class="docutils literal"><span class="pre">pycbc.workflow</span></code>)</a> &raquo;</li>
      
    <li>The workflow postprocessing preparation module</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/workflow/postprocprep.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="the-workflow-postprocessing-preparation-module">
<span id="workflowpostprocprepmod"></span><h1>The workflow postprocessing preparation module<a class="headerlink" href="#the-workflow-postprocessing-preparation-module" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The postprocessing preparation module is used to prepare the output of the coincidence stage for the postprocessing (ie. calculation of trigger significance and of rate statements). For the case of pipedown-style running this involves combining together all the trigger files adding in the injection and segment tables, performing injection finding and some clustering of coincident triggers.</p>
<p>The return from this module is a list of pycbc workflow File
objects corresponding to the output files to be directly used in the post-processing.</p>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>Using this module requires a number of things</p>
<ul class="simple">
<li>A configuration file (or files) containing the information needed to tell this module how to do the postprocessing preparation.</li>
<li>An initialized instance of the pycbc Workflow class, containing the ConfigParser.</li>
<li>A FileList returned by the coincidence module containing the triggers.</li>
<li>Other FileLists that may be needed by different methods, as described below.</li>
</ul>
<p>This module is then called according to</p>
<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.</code><code class="descname">setup_postprocessing_preparation</code><span class="sig-paren">(</span><em>workflow</em>, <em>triggerFiles</em>, <em>output_dir</em>, <em>tags=[]</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/postprocessing_prep.html#setup_postprocessing_preparation"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This function aims to be the gateway for preparing the output of the
coincidence and/or matched-filtering stages of the workflow for calculation 
of the significance of triggers and any rate statements that are to made. In
practice this normally means combining output files, performing any
clustering and performing mapping between triggers and simulations where
needed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>workflow</strong> : pycbc.workflow.core.Workflow</p>
<blockquote>
<div><p>The Workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>triggerFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the trigger files that are used as
input at this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output files will be stored.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;POSTPROC1&#8217;] or
[&#8216;DENTYSNEWPOSTPROC&#8217;]. This will be used in output names.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>postProcPreppedFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote class="last">
<div><p>A list of files that can be used as input for the post-processing stage.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="configuration-file-setup">
<h3>Configuration file setup<a class="headerlink" href="#configuration-file-setup" title="Permalink to this headline">¶</a></h3>
<p>Here we describe the options given in the configuration file used in the
workflow that will be needed in this section</p>
<div class="section" id="workflow-postprocprep-section">
<h4>[workflow-postprocprep] section<a class="headerlink" href="#workflow-postprocprep-section" title="Permalink to this headline">¶</a></h4>
<p>The configuration file must have a [workflow-postprocprep] section, which is used to provide instructions to the workflow module on how to set up the postprocessing preparation stage. The first option to choose and provide is</p>
<ul class="simple">
<li>postprocprep-method = VALUE</li>
</ul>
<p>The choices here and their description are as described below</p>
<ul class="simple">
<li>PIPEDOWN_WORKFLOW - This will prepare the output files for pipedown-style postprocessing. This involves combining all triggers, injection sets, segments into a single file, performing injection finding and performing clustering.</li>
</ul>
<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.</code><code class="descname">setup_postprocprep_pipedown_workflow</code><span class="sig-paren">(</span><em>workflow</em>, <em>coincFiles</em>, <em>output_dir</em>, <em>tags=[]</em>, <em>do_repop=False</em>, <em>injectionFiles=None</em>, <em>vetoFiles=None</em>, <em>injLessTag=None</em>, <em>injectionTags=[]</em>, <em>veto_cats=[]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/postprocessing_prep.html#setup_postprocprep_pipedown_workflow"><span class="viewcode-link">[source]</span></a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>workflow</strong> : pycbc.workflow.core.Workflow</p>
<blockquote>
<div><p>The Workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>coincFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the coincident trigger files that are used as
input at this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output files will be stored.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;POSTPROC1&#8217;] or
[&#8216;DENTYSNEWPOSTPROC&#8217;]. This will be used in output names.</p>
</div></blockquote>
<p><strong>do_repop</strong> : Boolean</p>
<blockquote>
<div><p>If False, use the &#8216;coinc_inspiral.snr&#8217; column from the coincident 
trigger files as clustering and ranking statistic; if True, use
a repop_coinc job before clustering to calculate a different ranking
statistic and store in the coinc_inspiral table for later use.</p>
</div></blockquote>
<p><strong>injectionFiles</strong> : pycbc.workflow.core.FileList (optional, default=None)</p>
<blockquote>
<div><p>The injection files to be used in this stage. An empty list (or any
other input that evaluates as false) is valid and will imply that no
injections are being done.</p>
</div></blockquote>
<p><strong>vetoFiles</strong> : pycbc.workflow.core.FileList (required)</p>
<blockquote>
<div><p>The data quality files to be used in this stage. This is required and
will be used to determine the analysed times when doing post-processing.</p>
</div></blockquote>
<p><strong>injLessTag</strong> : string (required)</p>
<blockquote>
<div><p>The tag that identifies files that do not have simulations in them.
Ie. the primary search results.</p>
</div></blockquote>
<p><strong>injectionTags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>Each injection file has a unique tag. If used in the method, this
tells the post-processing preparation code which injection tags it
should include when creating the combined output.</p>
</div></blockquote>
<p><strong>veto_cats</strong> : list of integers (optional, default = [])</p>
<blockquote>
<div><p>Decide which set of veto files should be used in the post-processing
preparation. For example tell the workflow to only generate results
at cumulative categories 2, 3 and 4 by supplying [2,3,4] here.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>finalFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>A list of the single SQL database storing the clustered, injection
found, triggers for all injections, time slid and zero lag analyses.</p>
</div></blockquote>
<p><strong>initialSqlFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>The SQL files before clustering is applied and injection finding
performed.</p>
</div></blockquote>
<p><strong>clusteredSqlFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>The clustered SQL files before injection finding performed.</p>
</div></blockquote>
<p><strong>combinedSqlFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote class="last">
<div><p>A combined file containing all triggers after clustering, including
the injection and veto tables, but before injection finding performed.
Probably there is no need to ever keep this file and it will be a
temporary file in most cases.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>With the PIPEDOWN_WORKFLOW method the following options apply</p>
<ul class="simple">
<li>postprocprep-combiner1-exe=NAME</li>
<li>postprocprep-combiner2-exe=NAME</li>
<li>postprocprep-cluster-exe=NAME</li>
<li>postprocprep-injfind-exe=NAME</li>
</ul>
<p>these specify which executables will be used for each step. These are described more fully below.</p>
<ul class="simple">
<li>PIPEDOWN_REPOP - This will prepare the output files for pipedown-style postprocessing including recalculation of the coinc ranking statistic before clustering. This involves combining all triggers, injection sets, segments into a single file, performing injection finding and performing clustering.</li>
</ul>
<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.</code><code class="descname">setup_postprocprep_pipedown_workflow</code><span class="sig-paren">(</span><em>workflow</em>, <em>coincFiles</em>, <em>output_dir</em>, <em>tags=[]</em>, <em>do_repop=False</em>, <em>injectionFiles=None</em>, <em>vetoFiles=None</em>, <em>injLessTag=None</em>, <em>injectionTags=[]</em>, <em>veto_cats=[]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/postprocessing_prep.html#setup_postprocprep_pipedown_workflow"><span class="viewcode-link">[source]</span></a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>workflow</strong> : pycbc.workflow.core.Workflow</p>
<blockquote>
<div><p>The Workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>coincFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the coincident trigger files that are used as
input at this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output files will be stored.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;POSTPROC1&#8217;] or
[&#8216;DENTYSNEWPOSTPROC&#8217;]. This will be used in output names.</p>
</div></blockquote>
<p><strong>do_repop</strong> : Boolean</p>
<blockquote>
<div><p>If False, use the &#8216;coinc_inspiral.snr&#8217; column from the coincident 
trigger files as clustering and ranking statistic; if True, use
a repop_coinc job before clustering to calculate a different ranking
statistic and store in the coinc_inspiral table for later use.</p>
</div></blockquote>
<p><strong>injectionFiles</strong> : pycbc.workflow.core.FileList (optional, default=None)</p>
<blockquote>
<div><p>The injection files to be used in this stage. An empty list (or any
other input that evaluates as false) is valid and will imply that no
injections are being done.</p>
</div></blockquote>
<p><strong>vetoFiles</strong> : pycbc.workflow.core.FileList (required)</p>
<blockquote>
<div><p>The data quality files to be used in this stage. This is required and
will be used to determine the analysed times when doing post-processing.</p>
</div></blockquote>
<p><strong>injLessTag</strong> : string (required)</p>
<blockquote>
<div><p>The tag that identifies files that do not have simulations in them.
Ie. the primary search results.</p>
</div></blockquote>
<p><strong>injectionTags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>Each injection file has a unique tag. If used in the method, this
tells the post-processing preparation code which injection tags it
should include when creating the combined output.</p>
</div></blockquote>
<p><strong>veto_cats</strong> : list of integers (optional, default = [])</p>
<blockquote>
<div><p>Decide which set of veto files should be used in the post-processing
preparation. For example tell the workflow to only generate results
at cumulative categories 2, 3 and 4 by supplying [2,3,4] here.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>finalFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>A list of the single SQL database storing the clustered, injection
found, triggers for all injections, time slid and zero lag analyses.</p>
</div></blockquote>
<p><strong>initialSqlFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>The SQL files before clustering is applied and injection finding
performed.</p>
</div></blockquote>
<p><strong>clusteredSqlFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>The clustered SQL files before injection finding performed.</p>
</div></blockquote>
<p><strong>combinedSqlFiles</strong> : pycbc.workflow.core.FileList</p>
<blockquote class="last">
<div><p>A combined file containing all triggers after clustering, including
the injection and veto tables, but before injection finding performed.
Probably there is no need to ever keep this file and it will be a
temporary file in most cases.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>With the PIPEDOWN_REPOP method the following options apply</p>
<ul class="simple">
<li>postprocprep-combiner1-exe=NAME</li>
<li>postprocprep-combiner2-exe=NAME</li>
<li>postprocprep-repop-exe=NAME</li>
<li>postprocprep-cluster-exe=NAME</li>
<li>postprocprep-injfind-exe=NAME</li>
</ul>
<p>these specify which executables will be used for each step. These are described more fully below.</p>
<ul class="simple">
<li>GSTLAL_POSTPROCPREP - This will perform the gstlal-style post-processing. This involves computing likelihood files, from there FAP and then some plotting routines.</li>
</ul>
<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.</code><code class="descname">setup_postprocprep_gstlal_workflow</code><span class="sig-paren">(</span><em>workflow</em>, <em>coinc_files</em>, <em>output_dir</em>, <em>tags=[]</em>, <em>injection_files=None</em>, <em>veto_files=None</em>, <em>inj_less_tag=None</em>, <em>injection_tags=[]</em>, <em>veto_cat=None</em>, <em>summary_xml_files=None</em>, <em>likelihood_files=[]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/postprocessing_prep.html#setup_postprocprep_gstlal_workflow"><span class="viewcode-link">[source]</span></a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>workflow</strong> : workflow.Workflow</p>
<blockquote>
<div><p>The workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>coinc_files</strong> : workflow.FileList</p>
<blockquote>
<div><p>An FileList of the coincident trigger files that are used as
input at this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output files will be stored.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;POSTPROC1&#8217;] or
[&#8216;DENTYSNEWPOSTPROC&#8217;]. This will be used in output names.</p>
</div></blockquote>
<p><strong>injection_files</strong> : workflow.FileList (optional, default=None)</p>
<blockquote>
<div><p>The injection files to be used in this stage. An empty list (or any
other input that evaluates as false) is valid and will imply that no
injections are being done.</p>
</div></blockquote>
<p><strong>veto_files</strong> : workflow.FileList (required)</p>
<blockquote>
<div><p>The data quality files to be used in this stage. This is required and
will be used to determine the analysed times when doing post-processing.</p>
</div></blockquote>
<p><strong>inj_less_tag</strong> : string (required)</p>
<blockquote>
<div><p>The tag that identifies files that do not have simulations in them.
Ie. the primary search results.</p>
</div></blockquote>
<p><strong>injection_tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>Each injection file has a unique tag. If used in the method, this
tells the post-processing preparation code which injection tags it
should include when creating the combined output.</p>
</div></blockquote>
<p><strong>veto_cat</strong> : int (optional, default = None)</p>
<blockquote>
<div><p>FIXME: How does gstlal deal with veto categories?
Hardcode to CAT1 for now.</p>
</div></blockquote>
<p><strong>summary_xml_files</strong> : workflow.FileList</p>
<blockquote>
<div><p>An FileList of the output of the analysislogging_utils module.
Here, this will be one file that includes the segments analysed by the
workflow.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>finalFiles</strong> : workflow.FileList</p>
<blockquote>
<div><p>A list of the single SQL database storing the clustered, injection
found, triggers for all injections, time slid and zero lag analyses.</p>
</div></blockquote>
<p><strong>initialSqlFiles</strong> : workflow.FileList</p>
<blockquote>
<div><p>The SQL files before clustering is applied and injection finding
performed.</p>
</div></blockquote>
<p><strong>clusteredSqlFiles</strong> : workflow.FileList</p>
<blockquote>
<div><p>The clustered SQL files before injection finding performed.</p>
</div></blockquote>
<p><strong>combinedSqlFiles</strong> : workflow.FileList</p>
<blockquote class="last">
<div><p>A combined file containing all triggers after clustering, including
the injection and veto tables, but before injection finding performed.
Probably there is no need to ever keep this file and it will be a
temporary file in most cases.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>With the GSTLAL_POSTPROCPREP method the following options apply</p>
<ul class="simple">
<li>postprocprep-runsqlite-exe=NAME</li>
<li>postprocprep-ligolwsqlite-exe=NAME</li>
<li>postprocprep-inspinjfind-exe=NAME</li>
<li>postprocprep-sqltoxml-exe=NAME</li>
<li>postprocprep-picklehor-exe=NAME</li>
<li>postprocprep-combllhood-exe=NAME</li>
<li>postprocprep-genranking-exe=NAME</li>
<li>postprocprep-compllhood-exe=NAME</li>
<li>postprocprep-marglikelihood-exe=NAME</li>
<li>postprocprep-fargstlal-exe=NAME</li>
<li>postprocprep-plotsummary-exe=NAME</li>
<li>postprocprep-plotsensitivity-exe=NAME</li>
<li>postprocprep-plotbackground-exe=NAME</li>
<li>postprocprep-summarypage-exe=NAME</li>
</ul>
<p>these specify which executables will be used for each step. These are described
more fully below.</p>
</div>
<div class="section" id="executables">
<h4>[executables]<a class="headerlink" href="#executables" title="Permalink to this headline">¶</a></h4>
<div class="section" id="for-the-pipedown-workflow-method">
<h5>For the PIPEDOWN_WORKFLOW method<a class="headerlink" href="#for-the-pipedown-workflow-method" title="Permalink to this headline">¶</a></h5>
<p>Executables required by this module are provided in the [executables] section. Any executable names specified in the [workflow-postprocprep] section must appear here. For instance if the [workflow-postprocprep] section reads</p>
<ul class="simple">
<li>postprocprep-combiner1-exe=pycbcsqlite</li>
<li>postprocprep-combiner2-exe=pycbcsqlite</li>
<li>postprocprep-cluster-exe=clustercoincs</li>
<li>postprocprep-injfind-exe=databaseinjfind</li>
</ul>
<p>you would need to have</p>
<ul class="simple">
<li>pycbcsqlite = ${which:pycbc_sqlite_simplify}</li>
<li>clustercoincs = ${which:ligolw_cbc_cluster_coincs}</li>
<li>databaseinjfind = ${which:ligolw_dbinjfind}</li>
</ul>
<p>in the [executables] section.</p>
<p>Sections, in this case [pycbcsqlite], [clustercoincs] and [databaseinjfind], will be used to specify the constant command line options that are sent to all jobs with the corresponding exe name. How to set up the [{exe_name}] section, and which executables are currently supported is discussed below.</p>
</div>
<div class="section" id="for-the-pipedown-repop-method">
<h5>For the PIPEDOWN_REPOP method<a class="headerlink" href="#for-the-pipedown-repop-method" title="Permalink to this headline">¶</a></h5>
<p>Executables required by this module are provided in the [executables] section. Any executable names specified in the [workflow-postprocprep] section must appear here. All the executables involved in the PIPEDOWN_WORKFLOW method are concerned here, plus in addition an executable to perform the recalculation of the coinc inspiral ranking statistic.
Thus if in the [workflow-postprocprep] section there is</p>
<p>(...)
* postprocprep-repop-exe=repopcoinc</p>
<p>you need to have (in addition to executables for the PIPEDOWN_WORKFLOW method)</p>
<ul class="simple">
<li>repopcoinc = ${which:ligolw_cbc_repop_coinc}</li>
</ul>
<p>in the [executables] section.</p>
<p>The ini file section [repopcoinc] will be used to specify the constant command line options that are sent to all jobs with this exe name. How to set up this section, and which executables are currently supported is discussed below.</p>
</div>
<div class="section" id="for-the-gstlal-postprocprep-method">
<h5>For the GSTLAL_POSTPROCPREP method<a class="headerlink" href="#for-the-gstlal-postprocprep-method" title="Permalink to this headline">¶</a></h5>
<p>Executables required by this module are provided in the [executables] section. Any executable names specified in the [workflow-postprocprep] section must appear here. For instance if the [workflow-postprocprep] section reads</p>
<ul class="simple">
<li>ADD</li>
</ul>
<p>you would need to have</p>
<ul class="simple">
<li>ADD</li>
</ul>
<p>in the [executables] section.</p>
<p>Sections will be used to specify the constant command line options that are sent to all jobs with the corresponding exe name. How to set up the [{exe_name}] section, and which executables are currently supported is discussed below.</p>
</div>
</div>
</div>
<div class="section" id="supported-post-processing-preparation-codes-and-instructions-for-using-them">
<h3>Supported post-processing preparation codes and instructions for using them<a class="headerlink" href="#supported-post-processing-preparation-codes-and-instructions-for-using-them" title="Permalink to this headline">¶</a></h3>
<div class="section" id="for-the-pipedown-workflow-and-pipedown-repop-methods">
<h4>For the PIPEDOWN_WORKFLOW and PIPEDOWN_REPOP methods<a class="headerlink" href="#for-the-pipedown-workflow-and-pipedown-repop-methods" title="Permalink to this headline">¶</a></h4>
<p>The following coincidence codes are currently supported in the workflow module:</p>
<div class="section" id="postprocprep-combiner1-exe">
<h5>postprocprep-combiner1-exe<a class="headerlink" href="#postprocprep-combiner1-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>pycbc_sqlite_simplify</li>
</ul>
</div>
<div class="section" id="postprocprep-combiner2-exe">
<h5>postprocprep-combiner2-exe<a class="headerlink" href="#postprocprep-combiner2-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>pycbc_sqlite_simplify</li>
</ul>
</div>
<div class="section" id="postprocprep-cluster-exe">
<h5>postprocprep-cluster-exe<a class="headerlink" href="#postprocprep-cluster-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ligolw_cbc_cluster_coincs</li>
</ul>
</div>
<div class="section" id="postprocprep-injfind-exe">
<h5>postprocprep-injfind-exe<a class="headerlink" href="#postprocprep-injfind-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ligolw_dbinjfind</li>
</ul>
</div>
<div class="section" id="postprocprep-repop-exe-only-for-pipedown-repop">
<h5>postprocprep-repop-exe (only for PIPEDOWN_REPOP)<a class="headerlink" href="#postprocprep-repop-exe-only-for-pipedown-repop" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ligolw_cbc_repop_coinc</li>
</ul>
</div>
</div>
<div class="section" id="id1">
<h4>For the GSTLAL_POSTPROCPREP method<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<div class="section" id="postprocprep-runsqlite-exe">
<h5>postprocprep-runsqlite-exe<a class="headerlink" href="#postprocprep-runsqlite-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-ligolwsqlite-exe">
<h5>postprocprep-ligolwsqlite-exe<a class="headerlink" href="#postprocprep-ligolwsqlite-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-inspinjfind-exe">
<h5>postprocprep-inspinjfind-exe<a class="headerlink" href="#postprocprep-inspinjfind-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-sqltoxml-exe">
<h5>postprocprep-sqltoxml-exe<a class="headerlink" href="#postprocprep-sqltoxml-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-picklehor-exe">
<h5>postprocprep-picklehor-exe<a class="headerlink" href="#postprocprep-picklehor-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-combllhood-exe">
<h5>postprocprep-combllhood-exe<a class="headerlink" href="#postprocprep-combllhood-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-genranking-exe">
<h5>postprocprep-genranking-exe<a class="headerlink" href="#postprocprep-genranking-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-compllhood-exe">
<h5>postprocprep-compllhood-exe<a class="headerlink" href="#postprocprep-compllhood-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-marglikelihood-exe">
<h5>postprocprep-marglikelihood-exe<a class="headerlink" href="#postprocprep-marglikelihood-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-fargstlal-exe">
<h5>postprocprep-fargstlal-exe<a class="headerlink" href="#postprocprep-fargstlal-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-plotsummary-exe">
<h5>postprocprep-plotsummary-exe<a class="headerlink" href="#postprocprep-plotsummary-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-plotsensitivity-exe">
<h5>postprocprep-plotsensitivity-exe<a class="headerlink" href="#postprocprep-plotsensitivity-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-plotbackground-exe">
<h5>postprocprep-plotbackground-exe<a class="headerlink" href="#postprocprep-plotbackground-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
<div class="section" id="postprocprep-summarypage-exe">
<h5>postprocprep-summarypage-exe<a class="headerlink" href="#postprocprep-summarypage-exe" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li>ADD</li>
</ul>
</div>
</div>
</div>
<div class="section" id="instructions-for-each-code">
<h3>Instructions for each code<a class="headerlink" href="#instructions-for-each-code" title="Permalink to this headline">¶</a></h3>
<p>Adding a new executable is not too hard, please ask a developer for some pointers on how to do this if you want to add a new code. This may require a new method if the new code uses a different method of generaring coincidences or time sliding.</p>
<p>The instructions for currently supported codes is given below</p>
<div class="section" id="pycbc-sqlite-simplify">
<h4>pycbc_sqlite_simplify<a class="headerlink" href="#pycbc-sqlite-simplify" title="Permalink to this headline">¶</a></h4>
<p>This code is responsible for combining together multiple xml or sql files into a single database. It also includes the code in dbsimplify for removing repeated entries to avoid the resulting database from getting too huge.</p>
<div class="highlight-text"><div class="highlight"><pre>$ pycbc_sqlite_simplify --help
usage: pycbc_sqlite_simplify [-h] [--version] -o OUTFILENAME [-p] [-t PATH]
                             [-i FILE] [-s TAG] [--vacuum] [-v]
                             INPUT_FILE [INPUT_FILE ...]

Add xml files to a SQLite database and simplify the output to remove redundant
or unused entries (basically a combination of ligolw_sqlite and
ligolw_cbc_dbsimplify)

positional arguments:
  INPUT_FILE            List of files to add to SQLITE database.

optional arguments:
  -h, --help            show this help message and exit
  --version             show program&#39;s version number and exit
  -o OUTFILENAME, --output-file OUTFILENAME
                        The name of the SQLite output file. If this exists it
                        will be overwritten.
  -p, --preserve-ids    Preserve row IDs from the XML in the database. The
                        default is to assign new IDs to prevent collisisions.
                        Inserts will fail if collisions occur.
  -t PATH, --tmp-space PATH
                        Path to a directory suitable for use as a work area
                        while manipulating the database file. The database
                        file will be worked on in this directory, and then
                        moved to the final location when complete. This option
                        is intended to improve performance when running in a
                        networked environment, where there might be a local
                        disk with higher bandwidth than is available to the
                        filesystem on which the final output will reside.
  -i FILE, --injection-file FILE
                        Injection file to add to the database and add in the
                        experiment tables.
  -s TAG, --simulation-tag TAG
                        Identifying string used to distinguish the injections
                        provided here from injections provided elsewhere once
                        they are combined. Required if injection-file is
                        given.
  --vacuum              If turned on, will vacuum the database before saving.
                        This cleans any fragmentation and removes empty space
                        left behind by all the DELETEs, making the output
                        database smaller and more efficient. WARNING: Since
                        this requires rebuilding the entire database, this can
                        take awhile for larger files.
  -v, --verbose         Be verbose.
</pre></div>
</div>
<p>Of these options the workflow module will automatically add the following, which are unique for each job. <strong>DO NOT ADD THESE OPTIONS IN THE CONFIGURATION FILE</strong>.</p>
<ul class="simple">
<li>&#8211;injection-file</li>
<li>&#8211;simulation-tag</li>
<li>&#8211;output-file</li>
<li>INPUT_FILE(s) (positional argument)</li>
</ul>
</div>
<div class="section" id="ligolw-cbc-cluster-coincs">
<h4>ligolw_cbc_cluster_coincs<a class="headerlink" href="#ligolw-cbc-cluster-coincs" title="Permalink to this headline">¶</a></h4>
<p>This code is used to perform a clustering stage on a set of coincident triggers.</p>
<div class="highlight-text"><div class="highlight"><pre>$ ligolw_cbc_cluster_coincs --help
Usage: ligolw_cbc_cluster_coincs [options]

Clusters coincident trigges in a database and writes result out to a new
database.

Options:
  --version             show program&#39;s version number and exit
  -h, --help            show this help message and exit
  -i INPUT, --input=INPUT
                        Input database to read. Can only input one at a time.
  -o OUTPUT, --output=OUTPUT
                        Name of output database to save to.
  -t PATH, --tmp-space=PATH
                        Requried. Location of local disk on which to do work.
                        This is used to enhance performance in a networked
                        environment, and to protect against accidently
                        overwriting the input database.
  -v, --verbose         Print progress information
  -D, --debug           Print SQLite queries used and the approximate time
                        taken to run each one.
  --param-name=PARAMETER
                        Can be any parameter in the param table (see --param-
                        table). Specifying this and param-ranges will only
                        cluster triggers that fall  within the parameter
                        range. Not specifying will cause all triggers in the
                        database to be clustered together.
  --param-ranges= [ LOW1, HIGH1 ); ( LOW2, HIGH2]; etc.
                        Requires --param-name. Specify the parameter ranges to
                        cluster triggers in. A &#39;(&#39; or &#39;)&#39; implies an open
                        boundary, a &#39;[&#39; or &#39;]&#39; a closed boundary. To specify
                        multiple ranges, separate each range by a &#39;;&#39;. Any
                        coincidences that fall outside of the union of all the
                        specified ranges will be deleted.
  --exclude-coincs= [COINC_INSTRUMENTS1 + COINC_INSTRUMENTS2 in INSTRUMENTS_ON1];[ALL in INSTRUMENTS_ON2]; etc.
                        Exclude coincident types in specified detector times,
                        e.g., &#39;[H2,L1 in H1,H2,L1]&#39;. Some rules: * Coinc-types
                        and detector time must be separated by an &#39; in &#39;. When
                        specifying a coinc_type or detector time, detectors
                        and/or ifos must be separated by commas, e.g. &#39;H1,L1&#39;
                        not &#39;H1L1&#39;. * To specify multiple coinc-types in one
                        type of time, separate each coinc-type by a &#39;+&#39;, e.g.,
                        &#39;[H1,H2 + H2,L1 in H1,H2,L1]&#39;. * To exclude all coincs
                        in a specified detector time or specific coinc-type in
                        all times, use &#39;ALL&#39;. E.g., to exclude all H1,H2
                        triggers, use &#39;[H1,H2 in ALL]&#39; or to exclude all H2,L1
                        time use &#39;[ALL in H2,L1]&#39;. * To specify multiple
                        exclusions, separate each bracket by a &#39;;&#39;. * Order of
                        the instruments nor case of the letters matter. So if
                        your pinky is broken and you&#39;re dyslexic you can type
                        &#39;[h2,h1 in all]&#39; without a problem.
  --include-only-coincs= [COINC_INSTRUMENTS1 + COINC_INSTRUMENTS2 in INSTRUMENTS_ON1];[ALL in INSTRUMENTS_ON2]; etc.
                        Opposite of --exclude-coincs: only the specified
                        coincs will be clusterd (all other coincs will be
                        deleted from the output database). To avoid confusing
                        overlaps, cannot specify both --exclude-coincs and
                        --include-only-coincs.
  --vacuum              If turned on, will vacuum the database before saving.
                        This cleans any fragmentation and removes empty space
                        left behind by all the DELETEs, making the output
                        database smaller and more efficient. WARNING: Since
                        this requires rebuilding the entire database, this can
                        take awhile for larger files.
  --time-column=TIME_COLUMN
                        Required. What column to use for the gps-time of
                        triggers. Should be set to end_time for inspiral
                        searches or start_time for ringdown searches. It is
                        assumed the the column specified has a corresponding
                        _ns column.
  --ranking-table=RANKING_TABLE
                        Required. What table to get the ranking-statsitic
                        from. Can be any table with a coinc_event_id. Ex.
                        coinc_inspiral.
  --ifos-table=IFOS_TABLE
                        What table to look in for the coincident ifos. Can be
                        any table with a coinc_event_id and an ifos column.
                        Default is to use whatever ranking-table is set to.
                        If, however, the specified ranking-table does not have
                        an ifos column (e.g., coinc_event), then this must be
                        specified.
  --param-table=PARAM_TABLE
                        If specifying a param-name and ranges, what table to
                        look in for the param values. Can be any table with a
                        coinc_event_id. Default is to use whatever ranking-
                        table is set to.
  --time-table=TIME_TABLE
                        What table to look in for the time column (see --time-
                        column). Can be any table with a coinc_event_id and
                        the specified time column. Default is to use whatever
                        ranking-table is set to. If, however, the specified
                        ranking-table does not have the time column (e.g., the
                        coinc_event table), then this must be specified.
  --cluster-window=CLUSTER_WINDOW
                        Required. Time window, in ms, to cluster triggers in.
  --ranking-stat=RANKING_STAT
                        Requried. The statistic to cluster on. Can be any
                        statistic in the coinc_inspiral table.
  --rank-by=MAX or MIN  Requried. Options are MAX or MIN. This specifies
                        whether to cluster triggers by maximum (MAX) or
                        minimum (MIN) stat value. Use MIN if clustering on
                        stats in which smaller is better (e.g., chisq, far).
                        Otherwise, use MAX.
  -G, --group-by-ifos   Turning on will cause triggers to be grouped by
                        coincident ifos when clustering.
  -M, --group-by-multiplicity
                        Turning on will cause triggers to be grouped by the
                        number of coincident ifos when clustering. For
                        example, doubles will be grouped with doubles, triples
                        with triples, etc. Note: if both --group-by-ifos and
                        --group-by-multiplicity on, group-by-ifos takes
                        precedence.
</pre></div>
</div>
<p>Of these options the workflow module will automatically add the following, which are unique for each job. <strong>DO NOT ADD THESE OPTIONS IN THE CONFIGURATION FILE</strong>.</p>
<ul class="simple">
<li>&#8211;input</li>
<li>&#8211;output</li>
</ul>
</div>
<div class="section" id="ligolw-dbinjfind">
<h4>ligolw_dbinjfind<a class="headerlink" href="#ligolw-dbinjfind" title="Permalink to this headline">¶</a></h4>
<p>This code is used to perform &#8220;injection finding&#8221; - it associates injection entries in the sim_inspiral table with coincident triggers in the coinc_inspiral table.</p>
<div class="highlight-text"><div class="highlight"><pre>$ ligolw_cbc_dbinjfind --help
Usage: %s --input INDB.SQLITE --output OUTDB.SQLITE --simulation-table SIM_TABLE --recovery-table SNGL_TABLE --match-criteria CRITERIA --map-label LABEL [options]

Options:
  -h, --help            show this help message and exit
  -i INPUT, --input=INPUT
                        Required. Database to update.
  -o OUTPUT, --output=OUTPUT
                        Required. Name of output database to save to.
  -t PATH, --tmp-space=PATH
                        Location of local disk on which to do work. This is
                        used to enhance performance in a networked
                        environment.
  -v, --verbose         Print progress information
  -s SIMULATION_TABLE, --simulation-table=SIMULATION_TABLE
                        Required. Name of table to look in for injections.
                        This table must have a simulation_id column.
  -r RECOVERY_TABLE, --recovery-table=RECOVERY_TABLE
                        Required. Name of (sngl) table to look in for events.
                        This table must have an event_id and an ifo column.
  -m SIM_CRITERIA[:REC_CRITERIA]:WINDOW_SIZE, --match-criteria=SIM_CRITERIA[:REC_CRITERIA]:WINDOW_SIZE
                        Required. The criteria to use to draw mappings, and
                        the size of that criteria to use. The criteria can be
                        either &#39;endTime&#39;, &#39;startTime&#39;, &#39;eThinca&#39;, or any math
                        operation on columns that are in the simulation-table
                        (for the sim-criteria) and the recovery table (for the
                        rec-criteria). If &#39;endTime&#39; or &#39;startTime&#39; are used,
                        the difference in time between the event&#39;s end/start
                        time and the end/start time for the corresponding IFO
                        in the simulation table is used. For example, for an
                        H1 event, the h_end_time column will be used in the
                        simulation table. The value after the colon specifies
                        the largest allowable difference between the injection
                        and the event for it to be mapped. The units of the
                        value correspond to what the criteria returns. For
                        endTime and startTime it is seconds; for eThinca, the
                        ethinca distance; for an arbitrary function, whatever
                        the value returned. If this argument is given multiple
                        times, all the specified match criteria must be
                        satisfied. For example, if &#39;-m endTime:endTime:0.2 -m
                        mass1+mass2:mtotal:0.1&#39; is specified, an event&#39;s end
                        time must be within 0.2s of the injected end time and
                        it&#39;s total mass must be within 0.1 of the injected
                        total mass.
  -M SIM_COLUMN:REC_COLUMN:WINDOW_SIZE, --rough-match=SIM_COLUMN:REC_COLUMN:WINDOW_SIZE
                        Use a rough cut before applying the match criteria.
                        This cuts down on the number  of times the match-
                        criteria must be executed between injections and sim-
                        inspiral events. Must be a single column in each
                        table; example: &#39;geocent_end_time:end_time:10&#39;. It is
                        STRONGLY recommended that you use this, as it will cut
                        down the execution time substantialy.
  -R CRITERIA:WINDOW_SIZE, --check-all-data=CRITERIA:WINDOW_SIZE
                        Check all_data (i.e., zero-lag data with no
                        injections) for an event with values of the given
                        column within the given window size. If an event is
                        found, then the corresponding event in simulation data
                        cannot be mapped to any injection. (The reasoning is
                        if the same event event exists in simulation data and
                        all_data, it cannot be from an injection.) The
                        specified column can be any math operation on any of
                        the columns in the recovery table. For example, if
                        &#39;end_time+end_time_ns*1e-9:0&#39; is specified, the end
                        time will be used; a window size of 0 means that the
                        events must have the exact same time to be considered
                        the same. This option can be specified multiple times.
                        If it is, all specified criteria must match in order
                        for an event not to be considered for injection
                        mapping.
  -X REC_COLUMN:WINDOW_SIZE, --rough-all-data-check=REC_COLUMN:WINDOW_SIZE
                        Use a rough check before applying the check-all-data
                        criteria. Must be a single column in the recovery
                        table; example: &#39;end_time:10&#39;. It is STRONGLY
                        recommended that you use this, as it will cut down the
                        execution time substantialy.
  -l MAP_LABEL, --map-label=MAP_LABEL
                        Required. What label to assign the mapping. This will
                        be stored in the coinc_definer&#39;s description column,
                        and will be used by later programs to pick out what
                        type of mapping to use for found and missed
                        injections. Typical inputs are &#39;exact&#39; and &#39;nearby&#39;.
                        Note: if this program is run multiple times on the
                        same database with the same map-label argument and
                        simulation/recovery tables, then later programs will
                        not be able to distinguish between the maps; i.e., all
                        injections mapped in all runs will be considered
                        &#39;found.&#39; For this reason, if the given map-label is
                        already found in the database between the given
                        simulation and recovery tables, an error will be
                        raised, unless --clear-map, --clear-coinc-type, or
                        --force are specified.
  -C, --clear-coinc-type
                        Delete all mappings in the database between the
                        simulation-table and the recovery-table that have the
                        same label as map-label prior to preforming the
                        injection finding.
  -A, --clear-map       Delete all mappings in the database that have the same
                        description as --map-label prior to drawing the new
                        mappings.
  -F, --force           Perform injection finding even if maps with the given
                        map-label already exist between the recovery-table and
                        simulation-table in the database.
  -S SEARCH, --search=SEARCH
                        Define the search type (ala &#39;inspiral&#39;,&#39;ringdown&#39;,
                        etc) which then will be stored in the search column of
                        the coinc_definer table. This is strictly for
                        labelling purposes, and it not required.
</pre></div>
</div>
<p>Of these options the workflow module will automatically add the following, which are unique for each job. <strong>DO NOT ADD THESE OPTIONS IN THE CONFIGURATION FILE</strong>.</p>
<ul class="simple">
<li>&#8211;input</li>
<li>&#8211;output</li>
</ul>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="postproc.html" class="btn btn-neutral float-right" title="The workflow postprocessing module" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="hdf_coincidence.html" class="btn btn-neutral" title="HDF5 Based Coincidence Code" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014, Alexander Nitz.
      Last updated on Nov 03, 2015.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>