

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>The workflow matched-filter module &mdash; PyCBC 1246c2 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="PyCBC 1246c2 documentation" href="../index.html"/>
        <link rel="up" title="Workflow: the inspiral analysis workflow generator (pycbc.workflow)" href="../workflow.html"/>
        <link rel="next" title="The workflow coincidence module" href="coincidence.html"/>
        <link rel="prev" title="The workflow table splitting module" href="splittable.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> PyCBC
          

          
          </a>

          
            
            
              <div class="version">
                1.5.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing PyCBC</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pycbc_make_psd_estimation_workflow.html"><code class="docutils literal"><span class="pre">pycbc_make_psd_estimation_workflow</span></code>: A workflow generator for noise estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pycbc_make_coinc_search_workflow.html"><code class="docutils literal"><span class="pre">pycbc_make_coinc_search_workflow</span></code>: A workflow to search for gravitational waves</a></li>
<li class="toctree-l1"><a class="reference internal" href="pycbc_make_sngl_workflow.html"><code class="docutils literal"><span class="pre">pycbc_make_sngl_workflow</span></code>: A single-ifo detchar workflow generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="pygrb.html"><code class="docutils literal"><span class="pre">pycbc_make_offline_grb_workflow</span></code>: A GRB triggered CBC analysis workflow generator</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pycbc_make_inference_workflow.html"><code class="docutils literal"><span class="pre">pycbc_make_inference_workflow</span></code>: A parameter estimation workflow generator</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tmpltbank.html">PyCBC template bank generation documentation (<code class="docutils literal"><span class="pre">pycbc.tmpltbank</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../inference.html">PyCBC inference documentation (<code class="docutils literal"><span class="pre">pycbc.inference</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hwinj.html">Hardware injection waveform generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../banksim.html">Calculating the Effectualness (Fitting Factor) of Template Banks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faithsim.html">Dag Generator for Doing Faithfulness Comparisons</a></li>
<li class="toctree-l1"><a class="reference internal" href="../upload_to_gracedb.html">Uploading triggers to gracedb</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../waveform.html">Waveforms</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../documentation.html">Documenting PyCBC code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release.html">Creating Releases of PyCBC</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../frame.html">Reading Gravitational-wave Frames (<code class="docutils literal"><span class="pre">pycbc.frame</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../formats/hdf_format.html">HDF files within the PyCBC workflow</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../workflow.html">Workflow: the inspiral analysis workflow generator (<code class="docutils literal"><span class="pre">pycbc.workflow</span></code>)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../workflow.html#introduction">Introduction</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../workflow.html#workflow-module-documentation">Workflow module documentation</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#basics-and-overview">Basics and overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#generating-segments">Generating segments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#obtaining-data">Obtaining data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#injection-generation">Injection generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#time-slide-generation">Time-slide generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#template-bank">Template bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#split-table">Split table</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../workflow.html#matched-filtering">Matched-filtering</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="">The workflow matched-filter module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#coincidence">Coincidence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#post-processing-preparation">Post processing preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../workflow.html#post-processing">Post-processing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../workflow.html#method-documentation">Method documentation</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">pycbc</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">PyCBC</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../workflow.html">Workflow: the inspiral analysis workflow generator (<code class="docutils literal"><span class="pre">pycbc.workflow</span></code>)</a> &raquo;</li>
      
    <li>The workflow matched-filter module</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/workflow/matched_filter.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="the-workflow-matched-filter-module">
<span id="workflowinspiralmod"></span><h1>The workflow matched-filter module<a class="headerlink" href="#the-workflow-matched-filter-module" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The matched-filter section of pycbc&#8217;s workflow module
is responsible for matched-filtering the
data against the template bank(s) from the template bank section and generating
a list of &#8220;triggers&#8221; for each interferometer. These triggers should be a list
of any event where the signal to noise ratio and any signal consistency test
are such that that point should be sent forward to check for coincidence in
other ifos.</p>
<p>Any single-ifo signal consistency tests (ie. chi-squared tests etc.) should
be computed in this section and stored within the lists of triggers. The
workflow
does not make any specifications on the output format, but obviously code in
the next stages of the workflow must know how to process that input.</p>
<p>The matched-filtering section should be as independent of the other stages of
the workflow as possible. This means that we don&#8217;t require the data read in by
matched-filter jobs to match that read in by template bank jobs (however this
may be desirable in some cases, so <strong>should</strong> be possible where sensible).
Options should also not be hardcoded (so there are no cases where an option
that gets sent to a template bank job also gets sent to a matched-filter job
without any way to stop that). However, it is possible to duplicate options
where this is desireable (see <a class="reference internal" href="initialization.html#workflowconfigparsermod"><span>Pycbc&#8217;s workflow module configuration file(s) and command line interface</span></a>).</p>
<p>The return from the matched-filter section of the workflow module
is a list of File
objects corresponding to each actual file (one for each job) that will be
generated within the workflow. This will be the <strong>only</strong> thing that will be
passed from the matched-filter section to the future sections.</p>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>Using this module requires a number of things</p>
<ul class="simple">
<li>A configuration file (or files) containing the information needed to tell this module how to generate GW triggers.</li>
<li>An initialized instance of the workflow class, containing the ConfigParser.</li>
<li>A list of segments to be analysed by this module.</li>
<li>A FileList returned by the templatebank module containing the template banks available for use.</li>
<li>A FileList returned by the datafind module containing the frames that contain the data that will be used to make the template banks.</li>
<li>If desired an injection file for assessing sensitivity to simulated signals.</li>
</ul>
<p>The module is then called according to</p>
<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.</code><code class="descname">setup_matchedfltr_workflow</code><span class="sig-paren">(</span><em>workflow</em>, <em>science_segs</em>, <em>datafind_outs</em>, <em>tmplt_banks</em>, <em>output_dir=None</em>, <em>injection_file=None</em>, <em>tags=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/matched_filter.html#setup_matchedfltr_workflow"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This function aims to be the gateway for setting up a set of matched-filter
jobs in a workflow. This function is intended to support multiple
different ways/codes that could be used for doing this. For now the only
supported sub-module is one that runs the matched-filtering by setting up
a serious of matched-filtering jobs, from one executable, to create
matched-filter triggers covering the full range of science times for which
there is data and a template bank file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>Workflow</strong> : pycbc.workflow.core.Workflow</p>
<blockquote>
<div><p>The workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>science_segs</strong> : ifo-keyed dictionary of glue.segments.segmentlist instances</p>
<blockquote>
<div><p>The list of times that are being analysed in this workflow.</p>
</div></blockquote>
<p><strong>datafind_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the datafind files that are needed to obtain the
data used in the analysis.</p>
</div></blockquote>
<p><strong>tmplt_banks</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the template bank files that will serve as input
in this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output will be stored.</p>
</div></blockquote>
<p><strong>injection_file</strong> : pycbc.workflow.core.File, optional (default=None)</p>
<blockquote>
<div><p>If given the file containing the simulation file to be sent to these
jobs on the command line. If not given no file will be sent.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;BNSINJECTIONS&#8217;] or
[&#8216;NOINJECTIONANALYSIS&#8217;]. This will be used in output names.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>inspiral_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote class="last">
<div><p>A list of output files written by this stage. This <em>will not</em> contain
any intermediate products produced within this stage of the workflow.
If you require access to any intermediate products produced at this
stage you can call the various sub-functions directly.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="configuration-file-setup">
<h3>Configuration file setup<a class="headerlink" href="#configuration-file-setup" title="Permalink to this headline">¶</a></h3>
<p>Here we describe the options given in the configuration file used in the
workflow that will be needed in this section</p>
<div class="section" id="workflow-matchedfilter-section">
<h4>[workflow-matchedfilter] section<a class="headerlink" href="#workflow-matchedfilter-section" title="Permalink to this headline">¶</a></h4>
<p>The configuration file must have an [workflow-matchedfilter] section, which is used to tell the workflow how to construct (or gather) the template banks. The first option to choose and provide is</p>
<ul class="simple">
<li>matchedfilter-method = VALUE</li>
</ul>
<p>The choices here and their description are as described below</p>
<ul class="simple">
<li>WORKFLOW_INDEPENDENT_IFOS - Matched-filter trigger files will be generated within the workflow. These banks will be made to cover only short (normally ~ 2000s) of data to reflect PSD changes over time and will be independent and distinct for each analysed interferometer. This uses the setup_matchedfltr_dax_generated sub-module.</li>
</ul>
<p>Currently only one option, but others can be added. The subfunctions used are described here</p>
<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.</code><code class="descname">setup_matchedfltr_dax_generated</code><span class="sig-paren">(</span><em>workflow</em>, <em>science_segs</em>, <em>datafind_outs</em>, <em>tmplt_banks</em>, <em>output_dir</em>, <em>injection_file=None</em>, <em>tags=None</em>, <em>link_to_tmpltbank=False</em>, <em>compatibility_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/matched_filter.html#setup_matchedfltr_dax_generated"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Setup matched-filter jobs that are generated as part of the workflow.
This
module can support any matched-filter code that is similar in principle to
lalapps_inspiral, but for new codes some additions are needed to define
Executable and Job sub-classes (see jobutils.py).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>workflow</strong> : pycbc.workflow.core.Workflow</p>
<blockquote>
<div><p>The Workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>science_segs</strong> : ifo-keyed dictionary of glue.segments.segmentlist instances</p>
<blockquote>
<div><p>The list of times that are being analysed in this workflow.</p>
</div></blockquote>
<p><strong>datafind_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the datafind files that are needed to obtain the
data used in the analysis.</p>
</div></blockquote>
<p><strong>tmplt_banks</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the template bank files that will serve as input
in this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output will be stored.</p>
</div></blockquote>
<p><strong>injection_file</strong> : pycbc.workflow.core.File, optional (default=None)</p>
<blockquote>
<div><p>If given the file containing the simulation file to be sent to these
jobs on the command line. If not given no file will be sent.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;BNSINJECTIONS&#8217;] or
[&#8216;NOINJECTIONANALYSIS&#8217;]. This will be used in output names.</p>
</div></blockquote>
<p><strong>link_to_tmpltbank</strong> : boolean, optional (default=True)</p>
<blockquote>
<div><p>If this option is given, the job valid_times will be altered so that there
will be one inspiral file for every template bank and they will cover the
same time span. Note that this option must also be given during template
bank generation to be meaningful.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>inspiral_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote class="last">
<div><p>A list of output files written by this stage. This <em>will not</em> contain
any intermediate products produced within this stage of the workflow.
If you require access to any intermediate products produced at this
stage you can call the various sub-functions directly.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>When using the setup_matchedfltr_dax_generated sub-module the following additional options apply in the [workflow-matchedfilter] section:</p>
<ul class="simple">
<li>matchedfilter-link-to-tmpltbank - OPTIONAL. If this is given the workflow module will attempt to ensure a one-to-one correspondence between template banks and matched-filter outputs. This may not work in all cases and should be considered an option to be used for comparing with ihope output.</li>
<li>matchedfilter-compatibility-mode - OPTIONAL. If this is given the workflow module will tile the matched-filter jobs in the same way as inspiral_hipe used to. This requires the link option above and that the template bank and matched-filtering jobs are reading the same amount of data in each job.</li>
<li>max-analysis-segments = (<em>NOT</em> used for lalapps_inspiral) - REQUIRED. The maximum number of analysis segments to analyze within a single inspiral job. Note that triggers may not be produced for the entire span of time.</li>
<li>min-analysis-segments = (<em>NOT</em> used for lalapps_inspiral) - REQUIRED. The minimum number of analysis segments to analyze within a single inspiral job. This may be the same as the maximum.</li>
</ul>
</div>
<div class="section" id="executables">
<h4>[executables]<a class="headerlink" href="#executables" title="Permalink to this headline">¶</a></h4>
<p>inspiral = /path/to/inspiral_exec</p>
<p>A section, in this case [inspiral], will be used to specify the constant command line options that are sent to all inspiral jobs. How to set up the [{exe_name}] section, and which executables are currently supported is discussed below.</p>
</div>
</div>
<div class="section" id="supported-inspiral-trigger-generators-and-instructions-for-using-them">
<h3>Supported inspiral trigger generators and instructions for using them<a class="headerlink" href="#supported-inspiral-trigger-generators-and-instructions-for-using-them" title="Permalink to this headline">¶</a></h3>
<p>The following inspiral trigger generators are currently supported in pycbc&#8217;s
workflow module</p>
<ul class="simple">
<li>lalapps_inspiral</li>
<li>pycbc_inspiral</li>
</ul>
<p>Adding a new executable is not too hard, please ask a developer for some pointers on how to do this if you want to add a new code.</p>
<div class="section" id="lalapps-inspiral-ahope">
<h4>lalapps_inspiral_ahope<a class="headerlink" href="#lalapps-inspiral-ahope" title="Permalink to this headline">¶</a></h4>
<p>Lalapps_inspiral is the legacy C-code that has been used for years to find gravitational-wave triggers in  It is a little inflexible in terms of output file names.</p>
<p>lalapps_inspiral is supported in the workflow module via a wrapper script lalapps_inspiral_ahope, this allows us to specify all the frame files and the output file name directly.</p>
<div class="highlight-text"><div class="highlight"><pre>$ lalapps_inspiral --help
lalapps_inspiral [options]

  --help                       display this message
  --verbose                    print progress information
  --version                    print version information and exit
  --user-tag STRING            set the process_params usertag to STRING
  --ifo-tag STRING             set the ifotag to STRING - for file naming
  --comment STRING             set the process table comment to STRING
  --gpu-device-id ID           set GPU device id (works only with Cuda enabled version) 

  --gps-start-time SEC         GPS second of data start time
  --gps-start-time-ns NS       GPS nanosecond of data start time
  --gps-end-time SEC           GPS second of data end time
  --gps-end-time-ns NS         GPS nanosecond of data end time
  --pad-data T                 pad the data start and end time by T seconds
  --slide-time T               slide data start epoch by T seconds
  --slide-time-ns T            slide data start epoch by T nanoseconds

  --glob-frame-data            glob *.gwf files in the pwd to obtain frame data
  --frame-type TAG             input data is contained in frames of type TAG
  --frame-cache                obtain frame data from LAL frame cache FILE
  --calibration-cache FILE     obtain calibration from LAL frame cache FILE
  --glob-calibration-data      obtain calibration by globbing in working dir

  --channel-name CHAN          read data from interferometer channel CHAN
  --calibrated-data TYPE       calibrated data of TYPE real_4 or real_8
  --strain-high-pass-freq F    high pass REAL8 h(t) data above F Hz
  --strain-high-pass-order O   set the order of the h(t) high pass filter to O
  --strain-high-pass-atten A   set the attenuation of the high pass filter to A
  --point-calibration          use the first point in the chunk to calibrate

  --injection-file FILE        inject simulated inspiral signals from FILE
  --fast F                     analyse injections templates within a match F
  --inject-overhead            inject signals from overhead detector
  --enable-filter-inj-only     filter only segments with injections
  --disable-filter-inj-only    filter all segments when doing injections
  --hardware-injection         Injections are in the frame files don&#39;t make them again!
                               All segments are filtered.

  --td-follow-up FILE          Follow up coincident BCV events in FILE
  --bank-file FILE             read template bank parameters from FILE
  --start-template N           start filtering at template number N in bank
  --stop-template N            stop filtering at template number N in bank
  --reverse-chirp-bank         filters data using a reverse chirp template bank

  --sample-rate F              filter data at F Hz, downsampling if necessary
  --resample-filter TYPE       set resample filter to TYPE (ldas|butterworth) 

  --disable-high-pass          turn off the IIR highpass filter
  --enable-high-pass F         high pass data above F Hz using an IIR filter
  --high-pass-order O          set the order of the high pass filter to O
  --high-pass-attenuation A    set the attenuation of the high pass filter to A
  --spectrum-type TYPE         use PSD estimator TYPE
                                 (mean|median|gaussian|white|LIGO|AdvLIGO) 
                               TYPE &#39;gaussian&#39; is equivalent to &#39;white&#39; - deprecated option

  --segment-length N           set data segment length to N points
  --number-of-segments N       set number of data segments to N
  --segment-overlap N          overlap data segments by N points

  --low-frequency-cutoff F     do not filter below F Hz
 --enable-dynamic-tmplt-flow   Use longest template that will fit in pad length
  --inverse-spec-length T      set length of inverse spectrum to T seconds
  --dynamic-range-exponent X   set dynamic range scaling to 2^X

  --approximant APPROX         set approximant of the waveform to APPROX
                               (FindChirpSP|BCV|BCVC|BCVSpin|TaylorT1|TaylorT2|IMRPhenomB
                                  TaylorT3|PadeT1|EOB|EOBNR|EOBNRv2|GeneratePPN|FindChirpPTF) 
  --order ORDER                set the pN order of the waveform to ORDER
                               (twoPN|twoPointFivePN|threePN|threePointFivePN|
                                  pseudoFourPN) 
  --snr-threshold RHO          set signal-to-noise threshold to RHO
  --chisq-bins P               set number of chisq veto bins to P
  --chisq-delta DELTA          set chisq delta parameter to DELTA
  --chisq-threshold X          threshold on chi^2 &lt; X * ( p + DELTA *rho^2 ) 
  --cluster-method MTHD        max over chirp MTHD (tmplt|window|tmpltwindow|none) 
  --cluster-window SEC         set length of clustering time window if required

  --enable-rsq-veto            enable the r^2 veto test
  --disable-rsq-veto           disable the r^2 veto test
  --rsq-veto-window SEC        set the r^2 veto window to SEC
  --rsq-veto-threshold RSQ     set r^2 veto threshold to RSQ

  --do-rsq-veto                do the r^2 veto
  --rsq-veto-time-thresh SEC   set the r^2 veto window to SEC
  --rsq-veto-max-snr MAXSNR    set the r^2 veto maximum snr to MAXSNR
  --rsq-veto-coeff COEFF       set the r^2 veto coefficient to COEFF
  --rsq-veto-pow POW           set the r^2 veto power to POW

  --bank-veto-subbank-size N   set the number of tmplts in a subbank to N
  --autochisq-length N         set the DOF of the autochisq to N in (1,1000)
  --autochisq-stride N         set the stride of the autochisq to N in (1,1000)
  --autochisq-two-sided        do a two-sided auto chisq test instead of one-sided.
  --bank-veto-time-freq        do a time-frequency bank veto. 

  --maximization-interval MSEC set length of interval (in ms) for
                                 maximization of triggers over the template bank.
                                 Cannot be used with --ts-cluster.

  --ts-cluster   MTHD          max over template and end time MTHD 
                                 (T0T3Tc|T0T3TcAS|Psi0Psi3Tc|Psi0Psi3TcAS) 
                                 Cannot be used with --maximization-interval.
  --ts-endtime-interval msec   set end-time interval for TrigScan clustering
  --ts-metric-scaling fac      scale the metric which defines the ellipsoids for TrigScan
                               Scaling must be &gt; 0


  --band-pass-template         Band-pass filter the time-domain inspiral template
  --taper-template OPT         Taper the inspiral template using option OPT
                                 (start|end|startend) 

  --cdata-length               Length of c-data snippet (in seconds) 
  --enable-output              write the results to a LIGO LW XML file
  --output-mask MASK           write the output sngl_inspiral table
                                 with optional MASK (bns|bcv) 
  --write-compress             write a compressed xml file
  --disable-output             do not write LIGO LW XML output file
  --trig-start-time SEC        only output triggers after GPS time SEC
  --trig-end-time SEC          only output triggers before GPS time SEC

  --white-gaussian VAR         replace data with white gaussian noise of variance VAR
  --gaussian-noise VAR         same as --white-gaussian - deprecated option
  --colored-gaussian PSD       replace data with colored gaussian noise with psd PSD
                               (LIGO|AdvLIGO) 

  --random-seed SEED           set random number seed for injections to SEED
                                 (urandom|integer) 

  --bank-simulation N          perform N injections to test the template bank
                                (sim_inspiral.xml|integer) 
  --enable-bank-sim-max        compute the maximum match over the bank
  --disable-bank-sim-max       do not maximize the match over the bank
  --sim-approximant APX        set approximant of the injected waveform to APX
                                 (TaylorT1|TaylorT2|TaylorT3|PadeT1|EOB|
                                  EOBNR|EOBNRv2|GeneratePPN|FrameFile) 
  --sim-frame-file F           read the bank sim waveform from frame named F
  --sim-frame-channel C        read the bank sim waveform from frame channel C
  --sim-minimum-mass M         set minimum mass of bank injected signal to M
  --sim-maximum-mass M         set maximum mass of bank injected signal to M
  --bank-sim-flower F          set low frequency of signal to F

  --data-checkpoint            checkpoint and exit after data is read in
  --checkpoint-path PATH       write checkpoint file under PATH
  --output-path PATH           write output data to PATH
  --username                   username for constructing output data PATH
  --compute-node-dir PATH      write output data to PATH on compute node

  --write-raw-data             write raw data to a frame file
  --write-filter-data          write data that is passed to filter to a frame
  --write-response             write the computed response function to a frame
  --write-spectrum             write the uncalibrated psd to a frame
  --write-snrsq                write the snr time series for each data segment
  --write-chisq                write the r^2 time series for each data segment
  --write-coh-trigs            write the trigger xml file when running in coherent stage
  --write-cdata                write the complex filter output
  --write-template                write the template time series
</pre></div>
</div>
<p>Of these options the workflow module or the wrapper script will automatically add the following, which are unique for each job. <strong>DO NOT ADD THESE OPTIONS IN THE CONFIGURATION FILE</strong>.</p>
<ul class="simple">
<li>&#8211;gps-start-time</li>
<li>&#8211;gps-end-time</li>
<li>&#8211;trig-start-time</li>
<li>&#8211;trig-end-time</li>
<li>&#8211;frame-cache</li>
<li>&#8211;user-tag</li>
<li>&#8211;ifo-tag</li>
</ul>
<p>All other options must be provided in the configuration file. Here is an example of a lalapps_inspiral call.</p>
<div class="highlight-bash"><div class="highlight"><pre>lalapps_inspiral --do-rsq-veto  --trig-end-time <span class="m">971614817</span> --enable-rsq-veto  --dynamic-range-exponent 69.0 --autochisq-stride <span class="m">2</span> --bank-file datafind/L1-TMPLTBANK_19-971612833-2048.xml.gz --high-pass-order <span class="m">8</span> --strain-high-pass-order <span class="m">8</span> --ifo-tag FULL_DATA --user-tag <span class="m">19</span> --gps-end-time <span class="m">971614881</span> --calibrated-data real_8 --channel-name L1:LDAS-STRAIN --snr-threshold 5.5 --cluster-method template --number-of-segments <span class="m">15</span> --trig-start-time <span class="m">971613852</span> --enable-high-pass 30.0 --gps-start-time <span class="m">971612833</span> --enable-filter-inj-only  --maximization-interval <span class="m">30</span> --high-pass-attenuation 0.1 --chisq-bins <span class="m">2</span> --inverse-spec-length <span class="m">16</span> --rsq-veto-threshold 15.0 --segment-length <span class="m">1048576</span> --low-frequency-cutoff 40.0 --pad-data <span class="m">8</span> --autochisq-two-sided  --sample-rate <span class="m">4096</span> --chisq-threshold 10.0 --rsq-veto-max-snr 12.0 --resample-filter ldas --strain-high-pass-atten 0.1 --strain-high-pass-freq <span class="m">30</span> --bank-veto-time-freq  --segment-overlap <span class="m">524288</span> --frame-cache datafind/L1-DATAFIND-968556757-3058132.lcf --chisq-delta 0.2 --bank-veto-subbank-size <span class="m">20</span> --approximant FindChirpSP --rsq-veto-time-thresh 0.0002 --write-compress  --autochisq-length <span class="m">100</span> --enable-output  --rsq-veto-window 6.0 --order threePointFivePN --spectrum-type median
</pre></div>
</div>
</div>
<div class="section" id="pycbc-inspiral">
<h4>pycbc_inspiral<a class="headerlink" href="#pycbc-inspiral" title="Permalink to this headline">¶</a></h4>
<p>pycbc_inspiral is pycbc&#8217;s inspiral matched-filtering program. Designed as a replacement and improvement of lalapps_inspiral. The help message of pycbc_inspiral follows:</p>
<div class="highlight-text"><div class="highlight"><pre>$ pycbc_inspiral --help
/home/cbc/pycbc/pycbc-virtualenv/lib/python2.6/site-packages/numpy/lib/utils.py:95: DeprecationWarning: `scipy.weave` is deprecated, use `weave` instead!
  warnings.warn(depdoc, DeprecationWarning)
__init__: Setting weave cache to /tmp/506_python26_compiled/1246c2/1246c23a0bdb96c91a574b939ee015ceaddf72ed
usage: 

Find single detector gravitational-wave triggers.

optional arguments:
  -h, --help            show this help message and exit
  --version             show program&#39;s version number and exit
  -V, --verbose         print extra debugging information
  --output OUTPUT       FIXME: ADD
  --bank-file BANK_FILE
                        FIXME: ADD
  --snr-threshold SNR_THRESHOLD
                        SNR threshold for trigger generation
  --newsnr-threshold THRESHOLD
                        Cut triggers with NewSNR less than THRESHOLD
  --low-frequency-cutoff LOW_FREQUENCY_CUTOFF
                        The low frequency cutoff to use for filtering (Hz)
  --max-template-length MAX_TEMPLATE_LENGTH
                        The maximum length of a template is seconds. The
                        starting frequency of the template is modified to
                        ensure the proper length
  --approximant APPRX[:COND] [APPRX[:COND] ...]
                        The approximant(s) to use. Multiple approximants to
                        use in different regions may be provided. If multiple
                        approximants are provided, every one but the last must
                        be be followed by a conditional statement defining
                        where that approximant should be used. Conditionals
                        can be any boolean test understood by numpy. For
                        example, &#39;Apprx:(mtotal &gt; 4) &amp; (mchirp &lt;= 5)&#39; would
                        use approximant &#39;Apprx&#39; where total mass is &gt; 4 and
                        chirp mass is &lt;= 5. Conditionals are applied in order,
                        with each successive one only applied to regions not
                        covered by previous arguments. For example,
                        `&#39;TaylorF2:mtotal &lt; 4&#39; &#39;IMRPhenomD:mchirp &lt; 3&#39;` would
                        result in IMRPhenomD being used where chirp mass is &lt;
                        3 and total mass is &gt;= 4. The last approximant given
                        may use &#39;else&#39; as the conditional or include no
                        conditional. In either case, this will cause the last
                        approximant to be used in any remaning regions after
                        all the previous conditionals have been applied. For
                        the full list of possible parameters to apply
                        conditionals to, see WaveformArray.default_fields().
                        Math operations may also be used on parameters; syntax
                        is python, with any operation recognized by numpy.
  --order {-1,0,1,2,3,4,5,6,7,8}
                        The integer half-PN order at which to generate the
                        approximant. Default is -1 which indicates to use
                        approximant defined default.
  --taper-template {start,end,startend}
                        For time-domain approximants, taper the start and/or
                        end of the waveform before FFTing.
  --cluster-method {template,window}
                        FIXME: ADD
  --cluster-function {findchirp,symmetric}
                        How to cluster together triggers within a window.
                        &#39;findchirp&#39; uses a forward sliding window; &#39;symmetric&#39;
                        will compare each window to the one before and after,
                        keeping only a local maximum.
  --cluster-window CLUSTER_WINDOW
                        Length of clustering window in seconds. Set to 0 to
                        disable clustering.
  --maximization-interval MAXIMIZATION_INTERVAL
                        Maximize triggers over the template bank (ms)
  --bank-veto-bank-file BANK_VETO_BANK_FILE
                        FIXME: ADD
  --chisq-snr-threshold CHISQ_SNR_THRESHOLD
                        Minimum SNR to calculate the power chisq
  --chisq-bins CHISQ_BINS
                        Number of frequency bins to use for power chisq.
                        Specify an integer for a constant number of bins, or a
                        function of template attributes. Math functions are
                        allowed, ex.
                        &#39;10./math.sqrt((params.mass1+params.mass2)/100.)&#39;.
                        Non-integer values will be rounded down.
  --chisq-threshold CHISQ_THRESHOLD
                        FIXME: ADD
  --chisq-delta CHISQ_DELTA
                        FIXME: ADD
  --autochi-number-points AUTOCHI_NUMBER_POINTS
                        The number of points to use, in both directions
                        ifdoing a two-sided auto-chisq, to calculate theauto-
                        chisq statistic.
  --autochi-stride AUTOCHI_STRIDE
                        The gap, in sample points, between the points atwhich
                        to calculate auto-chisq.
  --autochi-two-phase   If given auto-chisq will be calculated by testing
                        against both phases of the SNR time-series. If not
                        given, only the phase matching the trigger will be
                        used.
  --autochi-onesided {left,right}
                        Decide whether to calculate auto-chisq usingpoints on
                        both sides of the trigger or only on oneside. If not
                        given points on both sides will beused. If given, with
                        either &#39;left&#39; or &#39;right&#39;,only points on that side
                        (right = forward in time,left = back in time) will be
                        used.
  --autochi-reverse-template
                        If given, time-reverse the template beforecalculating
                        the auto-chisq statistic. This willcome at additional
                        computational cost as the SNRtime-series will need
                        recomputing for the time-reversed template.
  --autochi-max-valued  If given, store only the maximum value of the auto-
                        chisq over all points tested. A disadvantage of this
                        is that the mean value will not be known analytically.
  --autochi-max-valued-dof INT
                        If using --autochi-max-valued this value denotes the
                        pre-calculated mean value that will be stored as the
                        auto-chisq degrees-of-freedom value.
  --downsample-factor DOWNSAMPLE_FACTOR
                        Factor that determines the interval between the
                        initial SNR sampling. If not set (or 1) no sparse
                        sample is created, and the standard full SNR is
                        calculated.
  --upsample-threshold UPSAMPLE_THRESHOLD
                        The fraction of the SNR threshold to check the sparse
                        SNR sample.
  --upsample-method {pruned_fft}
                        The method to find the SNR points between the sparse
                        SNR sample.
  --user-tag TAG        This is used to identify FULL_DATA jobs for
                        compatibility with pipedown post-processing. Option
                        will be removed when no longer needed.
  --keep-loudest-interval KEEP_LOUDEST_INTERVAL
                        Window in seconds to maximize triggers over bank
  --keep-loudest-num KEEP_LOUDEST_NUM
                        Number of triggers to keep from each maximization
                        interval
  --gpu-callback-method GPU_CALLBACK_METHOD
  --threshold-template-filtering THRESHOLD_TEMPLATE_FILTERING

Options to select the method of PSD generation:
  The options --psd-model, --psd-file, --asd-file, and --psd-estimation are
  mutually exclusive.

  --psd-model {AdVBNSOptimizedSensitivityP1200087,AdVDesignSensitivityP1200087,AdVEarlyHighSensitivityP1200087,AdVEarlyLowSensitivityP1200087,AdVLateHighSensitivityP1200087,AdVLateLowSensitivityP1200087,AdVMidHighSensitivityP1200087,AdVMidLowSensitivityP1200087,AdvVirgo,GEO,GEOHF,KAGRA,TAMA,Virgo,aLIGOBHBH20Deg,aLIGOBHBH20DegGWINC,aLIGOBNSOptimizedSensitivityP1200087,aLIGODesignSensitivityP1200087,aLIGOEarlyHighSensitivityP1200087,aLIGOEarlyLowSensitivityP1200087,aLIGOHighFrequency,aLIGOHighFrequencyGWINC,aLIGOLateHighSensitivityP1200087,aLIGOLateLowSensitivityP1200087,aLIGOMidHighSensitivityP1200087,aLIGOMidLowSensitivityP1200087,aLIGONSNSOpt,aLIGONSNSOptGWINC,aLIGONoSRMHighPower,aLIGONoSRMLowPower,aLIGONoSRMLowPowerGWINC,aLIGOQuantumBHBH20Deg,aLIGOQuantumHighFrequency,aLIGOQuantumNSNSOpt,aLIGOQuantumNoSRMHighPower,aLIGOQuantumNoSRMLowPower,aLIGOQuantumZeroDetHighPower,aLIGOQuantumZeroDetLowPower,aLIGOThermal,aLIGOZeroDetHighPower,aLIGOZeroDetHighPowerGWINC,aLIGOZeroDetLowPower,aLIGOZeroDetLowPowerGWINC,eLIGOModel,eLIGOShot,iLIGOModel,iLIGOSRD,iLIGOSeismic,iLIGOShot,iLIGOThermal}
                        Get PSD from given analytical model.
  --psd-file PSD_FILE   Get PSD using given PSD ASCII file
  --asd-file ASD_FILE   Get PSD using given ASD ASCII file
  --psd-estimation {mean,median,median-mean}
                        Measure PSD from the data, using given average method.
  --psd-segment-length PSD_SEGMENT_LENGTH
                        (Required for --psd-estimation) The segment length for
                        PSD estimation (s)
  --psd-segment-stride PSD_SEGMENT_STRIDE
                        (Required for --psd-estimation) The separation between
                        consecutive segments (s)
  --psd-num-segments PSD_NUM_SEGMENTS
                        (Optional, used only with --psd-estimation). If given
                        PSDs will be estimated using only this number of
                        segments. If more data is given than needed to make
                        this number of segments than excess data will not be
                        used in the PSD estimate. If not enough data is given
                        the code will fail.
  --psd-inverse-length PSD_INVERSE_LENGTH
                        (Optional) The maximum length of the impulse response
                        of the overwhitening filter (s)
  --psd-output PSD_OUTPUT
                        (Optional) Write PSD to specified file

Options for obtaining h(t):
  These options are used for generating h(t) either by reading from a file
  or by generating it. This is only needed if the PSD is to be estimated
  from the data, ie. if the --psd-estimation option is given.

  --gps-start-time GPS_START_TIME
                        The gps start time of the data (integer seconds)
  --gps-end-time GPS_END_TIME
                        The gps end time of the data (integer seconds)
  --strain-high-pass STRAIN_HIGH_PASS
                        High pass frequency
  --pad-data PAD_DATA   Extra padding to remove highpass corruption (integer
                        seconds)
  --taper-data TAPER_DATA
                        Taper ends of data to zero using the supplied length
                        as a window (integer seconds)
  --sample-rate SAMPLE_RATE
                        The sample rate to use for h(t) generation (integer
                        Hz).
  --channel-name CHANNEL_NAME
                        The channel containing the gravitational strain data
  --frame-cache FRAME_CACHE [FRAME_CACHE ...]
                        Cache file containing the frame locations.
  --frame-files FRAME_FILES [FRAME_FILES ...]
                        list of frame files
  --frame-type FRAME_TYPE
                        (optional), replaces frame-files. Use datafind to get
                        the needed frame file(s) of this type.
  --fake-strain {AdVBNSOptimizedSensitivityP1200087,AdVDesignSensitivityP1200087,AdVEarlyHighSensitivityP1200087,AdVEarlyLowSensitivityP1200087,AdVLateHighSensitivityP1200087,AdVLateLowSensitivityP1200087,AdVMidHighSensitivityP1200087,AdVMidLowSensitivityP1200087,AdvVirgo,GEO,GEOHF,KAGRA,TAMA,Virgo,aLIGOBHBH20Deg,aLIGOBHBH20DegGWINC,aLIGOBNSOptimizedSensitivityP1200087,aLIGODesignSensitivityP1200087,aLIGOEarlyHighSensitivityP1200087,aLIGOEarlyLowSensitivityP1200087,aLIGOHighFrequency,aLIGOHighFrequencyGWINC,aLIGOLateHighSensitivityP1200087,aLIGOLateLowSensitivityP1200087,aLIGOMidHighSensitivityP1200087,aLIGOMidLowSensitivityP1200087,aLIGONSNSOpt,aLIGONSNSOptGWINC,aLIGONoSRMHighPower,aLIGONoSRMLowPower,aLIGONoSRMLowPowerGWINC,aLIGOQuantumBHBH20Deg,aLIGOQuantumHighFrequency,aLIGOQuantumNSNSOpt,aLIGOQuantumNoSRMHighPower,aLIGOQuantumNoSRMLowPower,aLIGOQuantumZeroDetHighPower,aLIGOQuantumZeroDetLowPower,aLIGOThermal,aLIGOZeroDetHighPower,aLIGOZeroDetHighPowerGWINC,aLIGOZeroDetLowPower,aLIGOZeroDetLowPowerGWINC,eLIGOModel,eLIGOShot,iLIGOModel,iLIGOSRD,iLIGOSeismic,iLIGOShot,iLIGOThermal,zeroNoise}
                        Name of model PSD for generating fake gaussian noise.
  --fake-strain-seed FAKE_STRAIN_SEED
                        Seed value for the generation of fake colored gaussian
                        noise
  --fake-strain-from-file FAKE_STRAIN_FROM_FILE
                        File containing ASD for generating fake noise from it.
  --injection-file INJECTION_FILE
                        (optional) Injection file used to add waveforms into
                        the strain
  --sgburst-injection-file SGBURST_INJECTION_FILE
                        (optional) Injection file used to add sine-Gaussian
                        burst waveforms into the strain
  --ringdown-injection-file RINGDOWN_INJECTION_FILE
                        (optional) Injection file used to add ringdown-only
                        waveforms into the strain.
  --injection-scale-factor INJECTION_SCALE_FACTOR
                        Divide injections by this factor before injecting into
                        the data.
  --gating-file GATING_FILE
                        (optional) Text file of gating segments to apply.
                        Format of each line is (all times in secs): gps_time
                        zeros_half_width pad_half_width
  --autogating-threshold SIGMA
                        If given, find and gate glitches producing a deviation
                        larger than SIGMA in the whitened strain time series.
  --autogating-cluster SECONDS
                        Length of clustering window for detecting glitches for
                        autogating.
  --autogating-width SECONDS
                        Half-width of the gating window.
  --autogating-taper SECONDS
                        Taper the strain before and after each gating window
                        over a duration of SECONDS.
  --autogating-pad SECONDS
                        Ignore the given length of whitened strain at the ends
                        of a segment, to avoid filters ringing.
  --normalize-strain NORMALIZE_STRAIN
                        (optional) Divide frame data by constant.
  --zpk-z ZPK_Z [ZPK_Z ...]
                        (optional) Zero-pole-gain (zpk) filter strain. A list
                        of zeros for transfer function
  --zpk-p ZPK_P [ZPK_P ...]
                        (optional) Zero-pole-gain (zpk) filter strain. A list
                        of poles for transfer function
  --zpk-k ZPK_K         (optional) Zero-pole-gain (zpk) filter strain.
                        Transfer function gain

Options for segmenting the strain:
  These options are used to determine how to segment the strain into smaller
  chunks, and for determining the portion of each to analyze for triggers.

  --trig-start-time TRIG_START_TIME
                        (optional) The gps time to start recording triggers
  --trig-end-time TRIG_END_TIME
                        (optional) The gps time to stop recording triggers
  --segment-length SEGMENT_LENGTH
                        The length of each strain segment in seconds.
  --segment-start-pad SEGMENT_START_PAD
                        The time in seconds to ignore of the beginning of each
                        segment in seconds.
  --segment-end-pad SEGMENT_END_PAD
                        The time in seconds to ignore at the end of each
                        segment in seconds.
  --filter-inj-only     Analyze only segments that contain an injection.
  --injection-window INJECTION_WINDOW
                        If using --filter-inj-only then only search for
                        injections within +/- injection window of the
                        injections&#39;s end time. This is useful to speed up a
                        coherent search or a search where we initially filter
                        at lower sample rate, and then filter at full rate
                        where needed. NOTE: Reverts to full analysis if two
                        injections are in the same segment.
  --allow-zero-padding  Allow for zero padding of data to analyze requested
                        times, if needed.

Options for selecting the processing scheme in this program.:
  --processing-scheme PROCESSING_SCHEME
                        The choice of processing scheme. Choices are [&#39;mkl&#39;,
                        &#39;cuda&#39;, &#39;cpu&#39;]. (optional for CPU scheme) The number
                        of execution threads can be indicated by
                        cpu:NUM_THREADS, where NUM_THREADS is an integer. The
                        default is a single thread. If the scheme is provided
                        as cpu:env, the number of threads can be provided by
                        the PYCBC_NUM_THREADS environment variable. If the
                        environment variable is not set, the number of threads
                        matches the number of logical cores.
  --processing-device-id PROCESSING_DEVICE_ID
                        (optional) ID of GPU to use for accelerated processing

Options for selecting the FFT backend and controlling its performance in this program.:
  --fft-backends [FFT_BACKENDS [FFT_BACKENDS ...]]
                        Preference list of the FFT backends. Choices are:
                        [&#39;lal&#39;, &#39;mkl&#39;, &#39;fftw&#39;, &#39;numpy&#39;]
  --lalfft-measure-level LALFFT_MEASURE_LEVEL
                        Determines the measure level used in planning LAL-
                        wrapped FFTs; allowed values are: [0, 1, 2, 3]
  --fftw-measure-level FFTW_MEASURE_LEVEL
                        Determines the measure level used in planning FFTW
                        FFTs; allowed values are: [0, 1, 2, 3]
  --fftw-threads-backend FFTW_THREADS_BACKEND
                        Give &#39;openmp&#39;, &#39;pthreads&#39; or &#39;unthreaded&#39; to specify
                        which threaded FFTW to use
  --fftw-input-float-wisdom-file FFTW_INPUT_FLOAT_WISDOM_FILE
                        Filename from which to read single-precision wisdom
  --fftw-input-double-wisdom-file FFTW_INPUT_DOUBLE_WISDOM_FILE
                        Filename from which to read double-precision wisdom
  --fftw-output-float-wisdom-file FFTW_OUTPUT_FLOAT_WISDOM_FILE
                        Filename to which to write single-precision wisdom
  --fftw-output-double-wisdom-file FFTW_OUTPUT_DOUBLE_WISDOM_FILE
                        Filename to which to write double-precision wisdom
  --fftw-import-system-wisdom
                        If given, call fftw[f]_import_system_wisdom()

Options for selecting optimization-specific settings:
  --cpu-affinity CPU_AFFINITY
                        A set of CPUs on which to run, specified in a format
                        suitable to pass to taskset.
  --cpu-affinity-from-env CPU_AFFINITY_FROM_ENV
                        The name of an enivornment variable containing a set
                        of CPUs on which to run, specified in a format
                        suitable to pass to taskset.

Options for controlling scipy.weave:
  --per-process-weave-cache
                        If given, each process will use a separate directory
                        for scipy.weave compilation. This is slower, but safer
                        if several instances may be starting on the same
                        machine at the same time.
  --clear-weave-cache-at-start
                        If given, delete the contents of the weave cache when
                        the process starts
  --clear-weave-cache-at-end
                        If given, delete the contents of the weave cache when
                        the process exits
  --fixed-weave-cache   If given, use fixed directory PWD/pycbc_inspiral for
                        the weave cache
</pre></div>
</div>
<p>Of these options the workflow module will automatically add the following, which are unique fo
r each job. <strong>DO NOT ADD THESE OPTIONS IN THE CONFIGURATION FILE</strong>.</p>
<ul class="simple">
<li>&#8211;gps-start-time</li>
<li>&#8211;gps-end-time</li>
<li>&#8211;frame-cache</li>
<li>&#8211;output</li>
</ul>
<p>All other options must be provided in the configuration file. Here is an example of a pycbc_inspiral call.</p>
<div class="highlight-bash"><div class="highlight"><pre>pycbc_inspiral --trig-end-time <span class="m">961592867</span> --verbose  --cluster-method window --bank-filetmpltbank/L1-TMPLTBANK_01-961591486-1382.xml.gz --gps-end-time <span class="m">961592884</span> --channel-name L1:LDAS-STRAIN --processing-scheme cuda --snr-threshold 5.5 --psd-estimation median --trig-start-time <span class="m">961591534</span> --gps-start-time <span class="m">961590836</span> --chisq-bins <span class="m">16</span> --segment-end-pad <span class="m">16</span> --segment-length <span class="m">2048</span> --low-frequency-cutoff <span class="m">15</span> --pad-data <span class="m">8</span> --cluster-window <span class="m">1</span> --sample-rate <span class="m">4096</span> --segment-start-pad <span class="m">650</span> --psd-segment-stride <span class="m">32</span> --psd-inverse-length <span class="m">16</span> --psd-segment-length <span class="m">64</span> --frame-cache datafind/L1-DATAFIND-961585543-7349.lcf --approximant SPAtmplt --output inspiral/L1-INSPIRAL_1-961591534-1333.xml.gz --strain-high-pass <span class="m">30</span> --order 7
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="pycbc-workflow-matched-filter-module">
<h2><a class="reference internal" href="../pycbc.workflow.html#module-pycbc.workflow.matched_filter" title="pycbc.workflow.matched_filter"><code class="xref py py-mod docutils literal"><span class="pre">pycbc.workflow.matched_filter</span></code></a> Module<a class="headerlink" href="#pycbc-workflow-matched-filter-module" title="Permalink to this headline">¶</a></h2>
<p>This is complete documentation of this module&#8217;s code</p>
<p>This module is responsible for setting up the matched-filtering stage of
workflows. For details about this module and its capabilities see here:
<a class="reference external" href="https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/NOTYETCREATED.html">https://ldas-jobs.ligo.caltech.edu/~cbc/docs/pycbc/NOTYETCREATED.html</a></p>
<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.matched_filter.</code><code class="descname">setup_matchedfltr_dax_generated</code><span class="sig-paren">(</span><em>workflow</em>, <em>science_segs</em>, <em>datafind_outs</em>, <em>tmplt_banks</em>, <em>output_dir</em>, <em>injection_file=None</em>, <em>tags=None</em>, <em>link_to_tmpltbank=False</em>, <em>compatibility_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/matched_filter.html#setup_matchedfltr_dax_generated"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Setup matched-filter jobs that are generated as part of the workflow.
This
module can support any matched-filter code that is similar in principle to
lalapps_inspiral, but for new codes some additions are needed to define
Executable and Job sub-classes (see jobutils.py).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>workflow</strong> : pycbc.workflow.core.Workflow</p>
<blockquote>
<div><p>The Workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>science_segs</strong> : ifo-keyed dictionary of glue.segments.segmentlist instances</p>
<blockquote>
<div><p>The list of times that are being analysed in this workflow.</p>
</div></blockquote>
<p><strong>datafind_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the datafind files that are needed to obtain the
data used in the analysis.</p>
</div></blockquote>
<p><strong>tmplt_banks</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the template bank files that will serve as input
in this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output will be stored.</p>
</div></blockquote>
<p><strong>injection_file</strong> : pycbc.workflow.core.File, optional (default=None)</p>
<blockquote>
<div><p>If given the file containing the simulation file to be sent to these
jobs on the command line. If not given no file will be sent.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;BNSINJECTIONS&#8217;] or
[&#8216;NOINJECTIONANALYSIS&#8217;]. This will be used in output names.</p>
</div></blockquote>
<p><strong>link_to_tmpltbank</strong> : boolean, optional (default=True)</p>
<blockquote>
<div><p>If this option is given, the job valid_times will be altered so that there
will be one inspiral file for every template bank and they will cover the
same time span. Note that this option must also be given during template
bank generation to be meaningful.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>inspiral_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote class="last">
<div><p>A list of output files written by this stage. This <em>will not</em> contain
any intermediate products produced within this stage of the workflow.
If you require access to any intermediate products produced at this
stage you can call the various sub-functions directly.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.matched_filter.</code><code class="descname">setup_matchedfltr_dax_generated_multi</code><span class="sig-paren">(</span><em>workflow</em>, <em>science_segs</em>, <em>datafind_outs</em>, <em>tmplt_banks</em>, <em>output_dir</em>, <em>injection_file=None</em>, <em>tags=None</em>, <em>link_to_tmpltbank=False</em>, <em>compatibility_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/matched_filter.html#setup_matchedfltr_dax_generated_multi"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Setup matched-filter jobs that are generated as part of the workflow in
which a single job reads in and generates triggers over multiple ifos.
This
module can support any matched-filter code that is similar in principle to
pycbc_multi_inspiral or lalapps_coh_PTF_inspiral, but for new codes some
additions are needed to define Executable and Job sub-classes
(see jobutils.py).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>workflow</strong> : pycbc.workflow.core.Workflow</p>
<blockquote>
<div><p>The Workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>science_segs</strong> : ifo-keyed dictionary of glue.segments.segmentlist instances</p>
<blockquote>
<div><p>The list of times that are being analysed in this workflow.</p>
</div></blockquote>
<p><strong>datafind_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the datafind files that are needed to obtain the
data used in the analysis.</p>
</div></blockquote>
<p><strong>tmplt_banks</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the template bank files that will serve as input
in this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output will be stored.</p>
</div></blockquote>
<p><strong>injection_file</strong> : pycbc.workflow.core.File, optional (default=None)</p>
<blockquote>
<div><p>If given the file containing the simulation file to be sent to these
jobs on the command line. If not given no file will be sent.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;BNSINJECTIONS&#8217;] or
[&#8216;NOINJECTIONANALYSIS&#8217;]. This will be used in output names.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>inspiral_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote class="last">
<div><p>A list of output files written by this stage. This <em>will not</em> contain
any intermediate products produced within this stage of the workflow.
If you require access to any intermediate products produced at this
stage you can call the various sub-functions directly.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">pycbc.workflow.matched_filter.</code><code class="descname">setup_matchedfltr_workflow</code><span class="sig-paren">(</span><em>workflow</em>, <em>science_segs</em>, <em>datafind_outs</em>, <em>tmplt_banks</em>, <em>output_dir=None</em>, <em>injection_file=None</em>, <em>tags=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pycbc/workflow/matched_filter.html#setup_matchedfltr_workflow"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This function aims to be the gateway for setting up a set of matched-filter
jobs in a workflow. This function is intended to support multiple
different ways/codes that could be used for doing this. For now the only
supported sub-module is one that runs the matched-filtering by setting up
a serious of matched-filtering jobs, from one executable, to create
matched-filter triggers covering the full range of science times for which
there is data and a template bank file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>Workflow</strong> : pycbc.workflow.core.Workflow</p>
<blockquote>
<div><p>The workflow instance that the coincidence jobs will be added to.</p>
</div></blockquote>
<p><strong>science_segs</strong> : ifo-keyed dictionary of glue.segments.segmentlist instances</p>
<blockquote>
<div><p>The list of times that are being analysed in this workflow.</p>
</div></blockquote>
<p><strong>datafind_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the datafind files that are needed to obtain the
data used in the analysis.</p>
</div></blockquote>
<p><strong>tmplt_banks</strong> : pycbc.workflow.core.FileList</p>
<blockquote>
<div><p>An FileList of the template bank files that will serve as input
in this stage.</p>
</div></blockquote>
<p><strong>output_dir</strong> : path</p>
<blockquote>
<div><p>The directory in which output will be stored.</p>
</div></blockquote>
<p><strong>injection_file</strong> : pycbc.workflow.core.File, optional (default=None)</p>
<blockquote>
<div><p>If given the file containing the simulation file to be sent to these
jobs on the command line. If not given no file will be sent.</p>
</div></blockquote>
<p><strong>tags</strong> : list of strings (optional, default = [])</p>
<blockquote>
<div><p>A list of the tagging strings that will be used for all jobs created
by this call to the workflow. An example might be [&#8216;BNSINJECTIONS&#8217;] or
[&#8216;NOINJECTIONANALYSIS&#8217;]. This will be used in output names.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>inspiral_outs</strong> : pycbc.workflow.core.FileList</p>
<blockquote class="last">
<div><p>A list of output files written by this stage. This <em>will not</em> contain
any intermediate products produced within this stage of the workflow.
If you require access to any intermediate products produced at this
stage you can call the various sub-functions directly.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="coincidence.html" class="btn btn-neutral float-right" title="The workflow coincidence module" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="splittable.html" class="btn btn-neutral" title="The workflow table splitting module" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014, Alexander Nitz.
      Last updated on Sep 25, 2016.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1246c2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>